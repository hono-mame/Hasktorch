# Linear Regression

### modelã¨ã¯ï¼Ÿ

â†’ ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’è¡¨ã™æ•°å­¦çš„ãªé–¢ä¿‚æ€§ã®ã“ã¨  
â†’ describes the relationship between input(s) and output

### ãªãœãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ï¼Ÿï¼Ÿ

â‘  ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã‹ã‚‰ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã ã‹ã‚‰

â‘¡ çµæœãŒæœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦äºˆæ¸¬ã§ãã‚‹


**ä¸€ç•ªã‚·ãƒ³ãƒ—ãƒ«ãªã®ãŒLinear Regression!**   

---

### Definition of regression
simple linear regression (å˜å›å¸°)  
$$y= a_0+a_1x_1$$

multiple linear regression (é‡å›å¸°)   
$$y= a_0+a_1x_1+ a_2x_2â€¦.$$


y: target (ç›®çš„å¤‰æ•°)

xn: feature (èª¬æ˜å¤‰æ•°)

an: model parameters (regression coefficients? , å›å¸°ä¿‚æ•°)


**ğŸŒŸ best fitã¨ãªã‚‹ã‚ˆã†ã«anã®å€¤ã‚’èª¿æ•´ã™ã‚‹! ğŸŒŸ**

---
### Definition of best fitï¼Ÿï¼Ÿ

**Error Term (e) : predicted - actual**

![](photos/LinearRegression1.png)

cost function â†’ æå¤±é–¢æ•°ãƒ»ã‚³ã‚¹ãƒˆé–¢æ•°

### How to minimize the Cost Function?

å˜ã«a0,a1â€¦ã®é–¢æ•°ã¨è¦‹ã‚Œã°ã„ã„ï¼  
â†“
**gradient descent algorhytm (å‹¾é…é™ä¸‹æ³•)**

![](photos/LinearRegression2.png)


if Î± is...  
big â†’ larger step, fast!!

small â†’ smaller step, slow :(

**step = Î±*fâ€™(a1)**

ğŸŒŸã‚¹ãƒ†ãƒƒãƒ—ãŒå¤§ãã„ã¨æœ€å°ã«ç„¡é™ã«ãŸã©ã‚Šç€ã‘ãªããªã£ã¦ã—ã¾ã†&å°ã•ã„ã¨æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¦ã—ã¾ã†ğŸŒŸ

**â†’ best way: set Î± to around 0.01**

Î±: hyper parameter
â†’a1,a2ãªã©ã«ã¯å½±éŸ¿ã—ãªã„ãŒã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å¤§ããå½±éŸ¿ã™ã‚‹!